I"^<h2 id="표본-분포">표본 분포</h2>

<p>전수조사는 실질적으로 불가능한 경우가 많으므로 <strong>표본 조사를 통해 모집단에 대한 해석을 진행하는 통계적 추론</strong>을 이용한다.</p>

<p>표본 조사는 반드시 초차가 발생하기 때문에 <strong>적절한 표본 추출 방법</strong>이 필요하다.</p>

<p>(<strong>표본과 모집단과의 관계 이해</strong>가 기반이 되어야 함)</p>

<p>랜덤넘버 생성기 (python)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">random</span>
<span class="p">[</span><span class="n">random</span><span class="p">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">)]</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="표본-평균의-분포">표본 평균의 분포</h2>

<p>표본조사를 통해서 파악하고자 하는 정보는 <strong>모수(parameter)</strong>이다.</p>

<p>모수 - 모평균, 모분산, 모비율 등..</p>

<p><strong>통계량(statistic)</strong> : 표본의 특성값(표본 평균, 표본 분산 등..)</p>

<p>표본의 평균은 표본의 선택에 따라 달라지고, 그렇기 때문에 <strong>표본평균도 하나의 확률변수</strong>이다.</p>

<p>통계량의 확률분포를 표본분포 (sampling distribution) 라고 한다.</p>

<p>평균이 $\mu$ 이고, 분산이 $\sigma^2$ 인 <strong>정규모집단에서</strong> 표본 n개를 추출하게 되면 그때 발생하는 표본평균의 확률변수 $\bar{X}$는 정규분포를 따른다.</p>

<ul>
  <li>표본평균 $\bar{x}={1\over n}\sum_{i=1}^nx_i$</li>
  <li>$\bar{X} \sim N(\mu,{\sigma^2\over n})$</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">xbars</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mean %f, var %f"</span> <span class="o">%</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xbars</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">var</span><span class="p">(</span><span class="n">xbars</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">xbars</span><span class="o">=</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">10</span><span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10000</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"mean %f, var %f"</span> <span class="o">%</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">xbars</span><span class="p">),</span> <span class="n">np</span><span class="p">.</span><span class="n">var</span><span class="p">(</span><span class="n">xbars</span><span class="p">)))</span>
<span class="kn">import</span> <span class="nn">matplotlib</span> <span class="k">as</span> <span class="n">plt</span>
<span class="n">h</span><span class="o">=</span><span class="n">plt</span><span class="p">.</span><span class="n">pyplot</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">xbars</span><span class="p">,</span> <span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">15</span><span class="p">),</span> <span class="n">bins</span><span class="o">=</span><span class="mi">30</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h3 id="중심극한정리central-limit-theorem">중심극한정리(central limit theorem)</h3>

<p>정규모집단이 아닌 일반 모집단에서 추출된 표본의 측정값으로 부터 추출한 표본평균의 확률변수는 $n \geqq 30$ 일 때 근사적으로 $\bar{X} \sim N(\mu,{\sigma^2\over n})$ 를 만족한다.</p>

<p><br /></p>

<h2 id="모평균의-추정">모평균의 추정</h2>

<h3 id="점추정">점추정</h3>

<p>표본평균이 점 추정값(추정량)이 된다.</p>

<p><br /></p>

<h3 id="구간추정">구간추정</h3>

<p>모평균 $\mu$의 $100(1-\alpha)%$% 신뢰구간 (confidence interval)</p>

<p>* 신뢰구간 : 100번 중에 x번은 추출한 표본들의 모평균 $\mu$가 포함될 것이라고 보장하는 구간</p>

<p><br /></p>

<ul>
  <li>정규분포에서 $\sigma$ 를 알 떄,</li>
</ul>

<center>$(\bar x -z_{\alpha/2}{\sigma \over \sqrt{n}},\;\;\;\;\;\; \bar x +z_{\alpha/2}{\sigma \over \sqrt{n}})$</center>

<p>* ($\mu$의 추정량) $\pm z_{\alpha/2}\times$(추정량의 표준편차)</p>

<ul>
  <li><strong>정규분포가 아니거나 표준편차를 모를 때</strong>는 실용적이지 못하다.</li>
  <li>표본의 크기가 클 때 중심극한 정리를 사용할 수 있다.</li>
</ul>

<center>$(\bar x -z_{\alpha/2}{s \over \sqrt{n}},\;\;\;\;\;\; \bar x +z_{\alpha/2}{s \over \sqrt{n}})$</center>

<p>(* $s$=표본표준편차)</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">w</span> <span class="o">=</span> <span class="p">[</span><span class="mf">10.7</span><span class="p">,</span> <span class="mf">11.7</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">11.4</span><span class="p">,</span> <span class="mf">10.8</span><span class="p">,</span> <span class="mf">9.9</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">8.8</span><span class="p">,</span> <span class="mf">12.2</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">11.3</span><span class="p">,</span> <span class="mf">11.1</span><span class="p">,</span> <span class="mf">10.3</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">9.9</span><span class="p">,</span> <span class="mf">11.1</span><span class="p">,</span> <span class="mf">11.7</span><span class="p">,</span> <span class="mf">11.5</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">,</span> <span class="mf">10.3</span><span class="p">,</span> <span class="mf">8.6</span><span class="p">,</span> <span class="mf">12.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">13.0</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">9.3</span><span class="p">,</span> <span class="mf">9.4</span><span class="p">,</span> <span class="mf">9.6</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">]</span>
<span class="n">xbar</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">sd</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># 표준편차를 구하는 메서드
</span>											<span class="c1"># ddof = 자유도 (delta degree of freedom) : 표본표준편차이기 때문에 전체 자유도에서 1만큼 차이난다.
</span><span class="k">print</span><span class="p">(</span><span class="s">"평균 %.2f, 표준편차: %.2f"</span> <span class="o">%</span><span class="p">(</span><span class="n">xbar</span><span class="p">,</span> <span class="n">sd</span><span class="p">))</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span>
<span class="n">zalpha</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span> <span class="c1"># 1-alpha/2 만큼에 해당하는 고지값을 구해주는 메서드
</span><span class="k">print</span><span class="p">(</span><span class="s">"zalpha: "</span><span class="p">,</span> <span class="n">zalpha</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="모비율의-추정">모비율의 추정</h3>

<ul>
  <li>n이 충분히 클때 $(n\hat p &gt;5,\;n(1-\hat p) &gt; 5$ 일 때$)$</li>
  <li>$X\sim N(np, np(1-p))$</li>
</ul>

<p><strong>확률변수 $X$의 표준화</strong></p>

<ul>
  <li>$Z={x-np \over \sqrt{n\hat{p}(1-\hat{p})}}={\hat{p}-p\over \sqrt{\hat{p}(1-\hat{p})\over n}}$</li>
  <li>근사적으로 표준정규분포 $N(0,1)$을 따른다.</li>
</ul>

<p><strong>구간추정</strong></p>

<table>
  <tbody>
    <tr>
      <td>$z_\alpha$ 의 정의 ⇒ $P(</td>
      <td>Z</td>
      <td>\leq z_{\alpha/2})=1-\alpha$</td>
    </tr>
  </tbody>
</table>

<p><br /></p>

<p>모비율 $p$의 $100(1-\alpha)$% 신뢰구간 (comfidence interval)<br /></p>

<p>⇒$(\hat p-z_{\alpha \over 2}\sqrt{\hat{p}(1-\hat{p})\over n}, \; \hat p+z_{\alpha \over 2}\sqrt{\hat{p}(1-\hat{p})\over n})$</p>

<p><br /></p>

<h2 id="검정">검정</h2>

<h3 id="통계적가설검정">통계적가설검정</h3>

<p>귀무가설 $H0:\mu -\mu_0$ (귀무가설을 일단 참이라 가정)</p>

<p>대립가설 $H1: \mu &gt; \mu_0$ (새로운 주장)</p>

<ul>
  <li>랜덤하게 선택한 표본에서 지금의 $\bar{X}$가 나올 확률을 계산하고, 이 확률이 낮다면 귀무가설이 참이 아니라고 판단한다.</li>
  <li>낮다는 기준점인 <strong>유의수준 $\alpha$</strong> 도입</li>
  <li>$P(\bar{X} \geq k) \leq \alpha$ 가 되는 $k$를 찾자.
    <ul>
      <li>$Z={\bar{X}-\mu \over {S/\sqrt n}}\sim N(0,1)$</li>
      <li>$P(Z \geq z_\alpha) =\alpha$</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p><strong>검정단계</strong></p>

<ol>
  <li>$H_0,\;H_1$ 설정</li>
  <li>유의수준 $\alpha$ 설정</li>
  <li>검정통계량 계산</li>
  <li>기각역 또는 임계값 계산</li>
  <li>주어진 데이터로부터 유의성 판정</li>
</ol>

<p><strong>기각역</strong></p>

<p>⇒ 대립가설이 무엇인가에 따라서 범위가 달라진다.</p>

<p>귀무가설이 $H_0:\mu=10.5$ 일때,</p>

<ul>
  <li>유의수준: $\mu$</li>
  <li>대립가설에 따라서 귀무가설을 기각할 수 있는 범위
    <ul>
      <li>$H_1:\mu&gt;10.5$ ⇒ $Z&gt;z_\alpha$</li>
      <li>$H_1:\mu&lt;10.5$ ⇒ $Z&lt;-z_\alpha$</li>
      <li>$H_1:\mu \neq 10.5$ ⇒ $\vert Z \vert &gt; z_{\alpha \over 2}$</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p><strong>예시)</strong></p>

<ul>
  <li>어떤 농장에서 자신들이 생각하는 계란의 평균 무게가 10.5 g 이라고 홍보하고 있다. 이에 생산된 계란 30개의 표본을 뽑았더니 그 무게가 아래와 같다.</li>
  <li>w=[10.7, 11.7, 9.8, 11.4, 10.8, 9.9, 10.1, 8.8, 12.2, 11.0, 11.3, 11.1, 10.3, 10.0, 9.9, 11.1, 11.7, 11.5, 9.1, 10.3, 8.6, 12.1, 10.0, 13.0, 9.2, 9.8, 9.3, 9.4, 9.6, 9.2]</li>
  <li>이 농장의 홍보가 맞는지 유의수준 5 % 로 검정하시오.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">w</span><span class="o">=</span><span class="p">[</span><span class="mf">10.7</span><span class="p">,</span> <span class="mf">11.7</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">11.4</span><span class="p">,</span> <span class="mf">10.8</span><span class="p">,</span> <span class="mf">9.9</span><span class="p">,</span> <span class="mf">10.1</span><span class="p">,</span> <span class="mf">8.8</span><span class="p">,</span> <span class="mf">12.2</span><span class="p">,</span> <span class="mf">11.0</span><span class="p">,</span> <span class="mf">11.3</span><span class="p">,</span> <span class="mf">11.1</span>
	<span class="p">,</span> <span class="mf">10.3</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">9.9</span><span class="p">,</span> <span class="mf">11.1</span><span class="p">,</span> <span class="mf">11.7</span><span class="p">,</span> <span class="mf">11.5</span><span class="p">,</span> <span class="mf">9.1</span><span class="p">,</span> <span class="mf">10.3</span><span class="p">,</span> <span class="mf">8.6</span><span class="p">,</span> <span class="mf">12.1</span><span class="p">,</span> <span class="mf">10.0</span><span class="p">,</span> <span class="mf">13.0</span>
	<span class="p">,</span> <span class="mf">9.2</span><span class="p">,</span> <span class="mf">9.8</span><span class="p">,</span> <span class="mf">9.3</span><span class="p">,</span> <span class="mf">9.4</span><span class="p">,</span> <span class="mf">9.6</span><span class="p">,</span> <span class="mf">9.2</span><span class="p">]</span>
<span class="n">mu</span> <span class="o">=</span> <span class="mf">10.5</span>
<span class="n">xbar</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
<span class="n">sd</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="n">std</span><span class="p">(</span><span class="n">w</span><span class="p">,</span> <span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"평균 %.2f, 표준편차: %.2f"</span> <span class="o">%</span> <span class="p">(</span><span class="n">xbar</span><span class="p">,</span> <span class="n">sd</span><span class="p">))</span>
<span class="n">z</span><span class="o">=</span><span class="p">(</span><span class="n">xbar</span><span class="o">-</span><span class="n">mu</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">sd</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">w</span><span class="p">)))</span>
<span class="k">print</span><span class="p">(</span><span class="s">"검정통계량: "</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
<span class="n">alpha</span><span class="o">=</span><span class="mf">0.05</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span>
<span class="n">cri</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">norm</span><span class="p">.</span><span class="n">ppf</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">alpha</span><span class="o">/</span><span class="mi">2</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"임계값: "</span><span class="p">,</span> <span class="n">cri</span><span class="p">)</span>
</code></pre></div></div>

<p><br /></p>

<h2 id="교차엔트로피">교차엔트로피</h2>

<h3 id="엔트로피">엔트로피</h3>

<p><strong>자기정보(self-information)</strong> : $i(A)$</p>

<ul>
  <li>$i(A)=log_b({1 \over P(A)})=-log_bP(A)$
    <ul>
      <li>자기 정보는 $A_j$를 표현하는 비트수</li>
    </ul>
  </li>
  <li>확률이 높은 사건은 정보가 많지 않음.
    <ul>
      <li>예) 도들이 들었을 때 개가 짖는 경우보다, 도둑이 들었는데도 개가 안 짖는 경우가 더 많은 정보를 포함하고 있다.</li>
    </ul>
  </li>
  <li>b는 정보의 단위로 <strong>2(bits)</strong>, e(nats), 10(hartleys) 를 사용함.</li>
</ul>

<p><br /></p>

<p><strong>엔트로피(entropy) 정의 : 자기정보의 평균</strong></p>

<center>$H(X)=\sum_jP(A_j)i(A_j)=-\sum_jP(A_j)log_2P(A_j)$</center>

<center>$(0 \leq H(X) \leq log_2K)$ </center>

<ul>
  <li>$K$는 사건의 수인데, 각 사건의 확률이 동일해서 $P(A_j)={1\over K}$ 일 때 $H(X)$가 최댓값을 가진다</li>
</ul>

<p>엔트로피는 ‘데이터를 표현할 때 필요한 평균비트수’ 이다.</p>

<h3 id="교차엔트로피-1">교차엔트로피</h3>

<p><strong>교차엔트로피 정의</strong></p>

<p>⇒두가지 확률분포 상에서 정확한 확률분포에 대해 다른 확률분포가 얼마나 차이나는지..</p>

<p>$H(P,Q)$ : 집합 S상에서 확률분포 P에 대한 확률분포 Q의 교차 엔트로피</p>

<ul>
  <li>정확한 확률분포 P를 사용했을 때의 비트수보다 항상 크다.
    <ul>
      <li>$H(P,Q)=-\sum_{x\in X}P(x)log_2Q(X) \geq -\sum_{x\in X}P(x)log_2P(x)=H(P)$</li>
    </ul>
  </li>
  <li>교차엔트로피는 결국 $P$와 $Q$가 얼마나 비슷한지를 나타낸다.
    <ul>
      <li>같을 때 ⇒ $H(P,Q)=H(P)$</li>
      <li>다를 때 ⇒ $H(P,Q)&gt;H(P)$</li>
    </ul>
  </li>
</ul>

<p><strong>(?) $H(P,Q) &lt;H(P)$ 일 때는?</strong></p>

<p><br /></p>

<p><strong>손실함수 : 학습의 방향을 알려주는 정보를 제공한다.</strong></p>

<p><strong>분류 문제에서의 손실함수</strong></p>

<ul>
  <li>기계학습에서는 주어진 대상이 각 그룹에 속할 확률을 제공하는데(예-[0.8, 0.2]), 이 값이 정답인 [1.0, 0.0] 과 얼마나 다른지 측정이 필요하다.</li>
  <li>원하는 답 $P=[p_1,p_2,\cdot\cdot\cdot,p_n],\; p_1+p_2+\cdot\cdot\cdot+p_n=1$</li>
  <li>제시된 답 $Q=[q_1,q_2,\cdot\cdot\cdot,q_n],\; q_1+q_2+\cdot\cdot\cdot+q_n=1$ 사이에 얼마나 다른지 척도가 필요하다.
    <ul>
      <li>제곱합
        <ul>
          <li>$\sum(p_i-q_i)^2$</li>
          <li>확률이 다를수록 큰 값을 가진다.</li>
          <li>하지만 <strong>학습 속도가 느리다.</strong></li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><br /></p>

<ul>
  <li>교차 엔트로피 $H(P,Q)$
    <ul>
      <li>확률이 다를수록 큰 값을 가진다.</li>
      <li><strong>학습 속도가 빠르다.</strong></li>
      <li>분류 문제에서 주로 이를 사용한다.</li>
    </ul>
  </li>
</ul>

<p><br /></p>

<p>기계학습의 분류 문제에서 원하는 답은 $P=[p_1,p_2,\cdot\cdot\cdot,p_n]$ 에서 하나만 1이고, 나머지는 0인 경우이다.</p>

<ul>
  <li>이 때, 엔트로피 $H(P)=0$ 이다.</li>
  <li>$P$ 중 하나인 $p_k=1.0$ 이라고 하면, $**q_k$의 값이 최대한 커지는 방향으로** 학습을 진행해야 한다.</li>
</ul>

<p><br /></p>

<p>교차엔트로피 구하기 실습</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="k">def</span> <span class="nf">crossentropy</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">Q</span><span class="p">):</span>
	<span class="k">return</span> <span class="nb">sum</span><span class="p">([</span><span class="o">-</span><span class="n">P</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="n">log2</span><span class="p">(</span><span class="n">Q</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">P</span><span class="p">))])</span>

<span class="n">P</span><span class="o">=</span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">0</span><span class="p">]</span>
<span class="n">Q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">crossentropy</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">Q</span><span class="p">))</span>
<span class="c1"># 결과 : 0.3219280948873623
</span><span class="n">Q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.5</span><span class="p">,</span><span class="mf">0.5</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">crossentropy</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">Q</span><span class="p">))</span>
<span class="c1"># 결과 : 1.0
</span><span class="n">Q</span><span class="o">=</span><span class="p">[</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">0.8</span><span class="p">]</span>
<span class="k">print</span><span class="p">(</span><span class="n">crossentropy</span><span class="p">(</span><span class="n">P</span><span class="p">,</span><span class="n">Q</span><span class="p">))</span>
<span class="c1"># 결과 : 2.321928094887362\
</span></code></pre></div></div>

<p><br /></p>

<p>참고 ) 다음주 알차게 보내는 법 소개 (from 이호준 멘토님)</p>

<ul>
  <li>numpy → 수학적인 내용들 복습 / 구현</li>
  <li>pandas → DataFrame 다루는 방법 → COVID-19 데이터 / 아보카도 데이터 분석 실습할 것</li>
  <li>matplotlib → 시각화 툴(Case Study) + seaborn → 직접 실습</li>
</ul>

<hr />

<ul>
  <li>EDA (E) : 탐색적 데이터 분석 → 어떤 데이터를 바탕으로 시각화와 인사이트 뽑아낼 수 있는 것이 목표</li>
</ul>

<p><strong>많은 노력이 필요할 것이라는데 무섭구만 🥶. . . .</strong></p>
:ET