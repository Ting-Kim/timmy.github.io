I"1<h2 id="인공지능과-기계학습-소개">인공지능과 기계학습 소개</h2>

<p><strong>일상 속 인공지능</strong></p>

<ul>
  <li>음성인식 (Siri)</li>
  <li>추천 시스템 (eBay, Netflix)</li>
  <li>자율주행 (Waymo)</li>
  <li>실시간 객체 인식 (Face ID)</li>
  <li>로봇 (HUBO)</li>
  <li>번역 (papago)</li>
</ul>

<p>강의에 사용되는 도서들은 다음과 같다.</p>

<ul>
  <li>기본도서 : 기계학습, 오일석</li>
  <li>참고도서
    <ul>
      <li>Machine Learning: a Probabilistic Perspective by K. Murphy</li>
      <li>Deep Learning by Goodfellow, Bengio, and Courville</li>
      <li>Stanford CS231N 강의자료</li>
    </ul>
  </li>
</ul>

<h2 id="기계학습1">기계학습1</h2>

<p>지식 기반 → 기계 학습 → 심층 학습(표현 학습)</p>

<p>결국 데이터 중심(경험 중심) 접근방식으로 전환..</p>

<p><strong>예측</strong>은 회귀문제와 분류문제로 나뉜다.</p>

<ul>
  <li>회귀는 목표치가 실수(연속적?)</li>
  <li>분류는 부류 혹은 종류의 값이다.</li>
</ul>

<p><strong>훈련</strong>은 최적의 파라미터(가중치)를 찾는 것.</p>

<p><strong>추론</strong></p>

<p>새로운 입력에 대한 목표치의 예측에 사용</p>

<p>테스트 집합에 대한 높은 성능을 <strong>일반화(generalization) 능력</strong>이라 한다.</p>

<p><strong>특징을 특징 벡터로 표기하는 이유</strong></p>

<ol>
  <li>벡터는 공간상에 표현할 수 있다.</li>
  <li>컴퓨터가 이해하기 쉬운 구조다.</li>
</ol>

<p>직선모델을 사용하는 경우 매개변수 수 = $d+1$</p>

<p>2차 곡선 모델을 사용하는 경우 매개변수 수 = $d^2+d+1$</p>

<p>결국 매개변수가 많아질수록 경험을 통해 찾아야 할 대상이 많아진다 → 모델의 자유도가 높아진다 → 학습이 복잡해지고 어려워진다.</p>

<p><strong>차원의 저주</strong></p>

<ul>
  <li>차원이 높아짐에 따라 발생하는 현실적인 문제들</li>
  <li>공간이 커지면 커질수록 데이터(경험)들이 지수적으로 더 많이 필요하다.</li>
</ul>

<p>공간 변환을 사용하면 풀지 못했던 원문제를 심플한 모델로 풀 수 있다. (표현 문제, 표현 학습)</p>

<p><strong>표현 학습</strong></p>

<ul>
  <li>좋은 특징 공간을 자동으로 찾는 작업</li>
</ul>

<p><strong>심층 학습</strong></p>

<p>표현학습의 하나로 <strong>다수의 은닉층을 가진 신경망</strong>을 이용하여 최적의 <strong>계층적인 특징</strong>을 학습</p>

<p><strong>기술 추세</strong></p>

<p>Rule-based system → Classic machine learning → Representation learning</p>

<ul>
  <li>Rule-based는 어떤 룰에 대해 수행</li>
  <li>Classic에서는 사람들의 지식을 포함시켜서 특정 규칙을 찾음</li>
  <li>Classic 과 Representation의 차이는 사람이 개입하냐 개입하지 않느냐 차이이다.</li>
</ul>

<p><strong>인공지능의 단계</strong></p>

<p>약인공지능 - 특정 task만 잘 품</p>

<p>강인공지능 - 인간이 할 수 있는 모든 지적인 업무 수행할 수 있음.</p>

<p>초인공지능 - 인간보다 훨씬 뛰어난 인공지능</p>

<h2 id="기계학습2">기계학습2</h2>

<p>적은 양의 데이터베이스로 어떻게 높은 성능을 달성하는가?</p>

<ul>
  <li>데이터 희소 가정
    <ul>
      <li>필요한 과업에 대한 학습에 관련없는 데이터 발생확률은 0에 가깝다.</li>
    </ul>
  </li>
  <li>매니폴드 가정
    <ul>
      <li>고차원의 데이터는 관련된 낮은 차원의 매니폴드에 가깝게 집중되어 있다.</li>
    </ul>
  </li>
</ul>

<p><strong>목적함수는 성능의 판단기준</strong></p>

<p>목적함수를 Loss가 최소가 되는 파라미터만을 찾는 것이 아닌, 내가 풀려고 하는 문제와 적합한 목적함수를 설정하는 것이 중요하다.</p>

<p>임의의 난수로 매개변수 값을 설정하고, 지속적으로 개선해서 최적해를 찾는다.</p>

<p><strong>최적화 이론</strong></p>

<ul>
  <li>Convex - 최적해 1개</li>
  <li>non-Convex - 최적해 존재할 수도, 안할 수도 있음. 신경망(gradient descent 방법)</li>
</ul>

<p><strong>기계 학습 알고리즘</strong></p>

<p>###</p>

<p>입력 : 훈련집합 X와 Y</p>

<p>출력 : 최적의 매개변수 $\hat{\theta}$</p>

<p>###</p>

<p>난수를 생성하여 초기 해 $\theta_1$을 설정한다.
$t=1$
while $j(\theta_t)$가 0, 0에 충분히 가깝지 않음:
$j(\theta_t)$가 작아지는 방향 $\vartriangle \theta_t$를 구한다.
$\theta_{t+1} = \theta_t + \vartriangle \theta_t$
$t=t+1$</p>

<p>$\hat\theta = \theta_t$</p>

<h2 id="기계학습-3">기계학습 3</h2>

<p>DL에서 신경망의 Capacity를 적절하게 낮추기 위해 최근에 규제를 많이 사용</p>

<p>자유도가 낮은 경우, 평향이 크고 비슷한 모델을 얻는다(분산이 작음) → 낮은 변동</p>

<p>자유도가 높은 경우, 편향이 적고 크게 다른 모델을 얻는다(분산이 큼) → 높은 변동</p>

<p>(편향과 분산은 trade-off 관계이다.)</p>

<p><strong>기계 학습의 목표</strong></p>

<ul>
  <li>target의 용량 == model 용량</li>
  <li>낮은 평향과 낮은 분산을 가진 예측 모델을 만드는 것</li>
</ul>

<p><strong>편향과 분산의 관계</strong></p>

<p><img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTibnw8GyN-tRkM6i4ina1SG-5yN6O3gJPvnA&amp;usqp=CAU" alt="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTibnw8GyN-tRkM6i4in0a1SG-5yN6O3gJPvnA&amp;usqp=CAU" /></p>

<p>출처:https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fcedar.buffalo.edu%2F~srihari%2FCSE676%2F5.2%2520MLBasics-Capacity.pdf&amp;psig=AOvVaw1mxejLIe0v21OnjBFZjvkX&amp;ust=1611067718297000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCOi9047dpe4CFQAAAAAdAAAAABAE</p>

<p><br /></p>

<p>Underfitting은 보통 Bias, Overfitting은 Variance 때문에 발생</p>

<p>Generalization error를 최소로 하는 방법은 크게 일단 용량을 잡고 Regularize 로 깎는 방식을 최근에 사용</p>

<p><strong>Validation set을 이용한 모델 선택</strong></p>

<p>훈련데이터가 많을 때 부분 분할 하여 Validation set으로 사용</p>

<p>###(알고리즘) 검증집합을 이용한 모델 선택</p>

<p>for ($\Omega$(모델집합)에 있는 각각의 모델):</p>

<p>모델을 훈련집합으로 학습시킨다.</p>

<p>검증집합으로 학습된 모델의 성능을 측정한다.</p>

<p>가장 높은 성능을 보인 모델을 선택한다.</p>

<p>테스트 집합으로 선택된 모델의 성능을 측정한다.</p>

<p>###</p>

<p><img src="https://github.com/Ting-Kim/Ting-kim.github.io/blob/main/images/20210118_1.png?raw=true" alt="https://github.com/Ting-Kim/Ting-kim.github.io/blob/main/images/20210118_1.png?raw=true" /></p>

<p><strong>교차검증(Cross Validation)</strong></p>

<p>데이터 양이 적을 때(검증집합이 없을 때), 유용한 모델 선택 기법</p>

<p><img src="https://s3.amazonaws.com/higherlogicdownload/H2OAI/UploadedImages/Vcn3hx77RcGlSBB3RI69_16.png" alt="https://s3.amazonaws.com/higherlogicdownload/H2OAI/UploadedImages/Vcn3hx77RcGlSBB3RI69_16.png" /></p>

<p>출처:https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fwww.h2o.ai%2Fcommunity%2Fglossary%2Fmodel-validation-hold-out-cross-validation&amp;psig=AOvVaw1IjMiVbJl16_Nd2FKF-s7X&amp;ust=1611067692578000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCJio_IHdpe4CFQAAAAAdAAAAABAD</p>

<p><br /></p>

<p>데이터 양이 많을 때 검증집합은 어느정도 치우칠 수 있는데, 여기서는 Validation set을 여러 번 돌려서 평균을 도출하기 때문에 적은 양으로도 고도화된 일반화 성능을 확인할 수 있다.</p>

<p><strong>부트스트랩(Bootstrap)</strong></p>

<ul>
  <li>임의의 복원 추출 샘플링(sampling with replacement) 반복</li>
  <li>데이터 분포가 불균형일 때 적용(데이터 분포에 치우침이 있을 때)</li>
  <li>이상탐지, 보안 문제에서 많이 사용</li>
</ul>

<p><img src="https://miro.medium.com/max/1010/1*YYom-NKDaZ-B7RB_891DgQ.png" alt="bootstrap_data_sampling" /></p>

<p>출처:https://www.google.com/url?sa=i&amp;url=https%3A%2F%2Fmedium.com%2Ftime-to-work%2Fbagging-classifier-6261138b92d4&amp;psig=AOvVaw1czCwKX8GYaOq6sWoPnvNc&amp;ust=1611068723452000&amp;source=images&amp;cd=vfe&amp;ved=0CAIQjRxqFwoTCMiayergpe4CFQAAAAAdAAAAABAO</p>

<p><br /></p>

<p>###(알고리즘) 부트스트랩을 이용한 모델 선택</p>

<p>입력 : 모델집합 $\Omega$, 훈련집합, 테스트집합, 샘플링 비율 $p(0&lt;p\leq 1)$, 반복횟수 $T$</p>

<p>출력 : 최적 모델과 성능</p>

<hr />

<p>for ($\Omega$(모델집합)에 있는 각각의 모델)</p>

<p>for ($i=1$ to $T$)</p>

<p>훈련집합 $X$에서 $pn$개 샘플을 뽑아 새로운 훈련집합 $X’$를 구성한다. 이때 대치를 허용한다.</p>

<p>$X’$로 모델을 학습시킨다.</p>

<p>$X-X’$를 이용하여 학습된 모델의 성능을 측정한다.</p>

<p>$T$개 성능을 평균하여 해당 모델의 성능으로 취한다.</p>

<p>가장 높은 성능을 보인 모델을 선택한다.</p>

<p>테스트집합으로 선택된 모델의 성능을 측정한다.</p>

<p>###</p>

<p><strong>데이터 확대(data augmentation)</strong></p>

<ul>
  <li>데이터 수집은 많은 비용이 든다</li>
  <li>훈련집합의 샘플들을 변형(transform)한다. (원 데이터의 부류, 속성 등의 고유 특성 변하지 않을 만큼의 약간의 회전(rotation) 혹은 왜곡(warping))</li>
</ul>

<p><strong>가중치 감쇠</strong></p>

<ul>
  <li>개선된 목적함수를 이용하여 가중치를 작게 조절하는 규제 기법
    <ul>
      <li>목적함수에 규제 항(preference, 선호)을 추가하여 가중치 크기를 작게 유지해준다.</li>
      <li>$\lambda$는 주어진 가중치의 감쇠 선호 정도를 제어
        <ul>
          <li>$\lambda=0$ : 감쇠 없음</li>
          <li>큰 $\lambda$는 가중치를 더 작아지도록 한다</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p><strong>규제</strong></p>

<p><strong>지도 학습</strong></p>

<ul>
  <li>특징 벡터 X와 목표치 Y(정답 있음)가 모두 주어진 상황</li>
  <li>보통 회귀와 분류 문제로 구분한다.</li>
</ul>

<p><strong>비지도 학습</strong></p>

<ul>
  <li>특징 벡터 X는 주어지나, 목표치 Y가 주어지지 않는 상황 (정답이 없음)</li>
  <li>군집화(clustering) 과업 (추천시스템, 고객 성향에 따른 맞춤 홍보 응용 등)</li>
  <li>Density estimation, 특징 공간 변환 과업 (예. PCA)</li>
</ul>

<p><strong>강화 학습</strong></p>

<ul>
  <li>상대적 목표치가 주어지는데, 지도 학습과 다른 형태 (Agent의 Action을 통해 상황이 변경되는 것을 반영(보상(Reward)))</li>
  <li>환경에 interactive한 상호작용을 통해서 학습하는 형태</li>
</ul>

<p><strong>준지도 학습</strong></p>

<ul>
  <li>일부는 X, Y를 모두 가지지만, 나머지는 X만 가진 상황</li>
  <li>Y 데이터는 수작업이 필요하므로 최근 기업들이 많이 푸려고 하는 문제이다.</li>
</ul>

<p><strong>오프라인 학습, 온라인 학습</strong></p>

<ul>
  <li>보통 오프라인 학습</li>
  <li>온라인 학습은 추가로 발생하는 데이터에 대해 점증적 학습 수행</li>
</ul>

<p><strong>결정론적 학습(deterministic learning)과 확률적 학습(Stochastic learning)</strong></p>

<ul>
  <li>결정론에서는 같은 데이터를 가지고 재학습 시 같은 예측 모델이 생성됨</li>
  <li>확률적 학습은 학습 과정에서 확률 분포를 사용하므로 같은 데이터로 재학습하면 다른 예측 모델이 만들어진다. (ex. RBM, DBN)</li>
</ul>

<p><strong>분별 모델(discriminative models)과 생성 모델(generative models)</strong></p>

<ul>
  <li>
    <table>
      <tbody>
        <tr>
          <td>분별 모델은 P(y</td>
          <td>x)의 추정에만 관심</td>
        </tr>
      </tbody>
    </table>
  </li>
  <li>
    <table>
      <tbody>
        <tr>
          <td>생성 모델은 P(x) or P(x</td>
          <td>y)를 추정한다.</td>
        </tr>
      </tbody>
    </table>
    <ul>
      <li>새로운 샘플을 생성할 수 있음</li>
      <li>GAN, RBM은 생성 모델이다.</li>
      <li>RNN(순환신경망)을 생성 모델로 활용하는 응용 예제도 있다.</li>
    </ul>
  </li>
</ul>
:ET