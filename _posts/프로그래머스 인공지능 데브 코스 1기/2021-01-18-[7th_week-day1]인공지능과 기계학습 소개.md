---
layout: post
title: "[Deep learning]Introduction of AI and Machine learning"
tags: [Machine learning, deep learning, ai]
use_math: true
comments: true
---

## 인공지능과 기계학습 소개

**일상 속 인공지능**

- 음성인식 (Siri)
- 추천 시스템 (eBay, Netflix)
- 자율주행 (Waymo)
- 실시간 객체 인식 (Face ID)
- 로봇 (HUBO)
- 번역 (papago)

강의에 사용되는 도서들은 다음과 같다.

- 기본도서 : 기계학습, 오일석
- 참고도서
  - Machine Learning: a Probabilistic Perspective by K. Murphy
  - Deep Learning by Goodfellow, Bengio, and Courville
  - Stanford CS231N 강의자료

## 기계학습1

지식 기반 → 기계 학습 → 심층 학습(표현 학습)

결국 데이터 중심(경험 중심) 접근방식으로 전환..

**예측**은 회귀문제와 분류문제로 나뉜다.

- 회귀는 목표치가 실수(연속적?)
- 분류는 부류 혹은 종류의 값이다.

**훈련**은 최적의 파라미터(가중치)를 찾는 것.

**추론**

새로운 입력에 대한 목표치의 예측에 사용

테스트 집합에 대한 높은 성능을 **일반화(generalization) 능력**이라 한다.

**특징을 특징 벡터로 표기하는 이유**

1. 벡터는 공간상에 표현할 수 있다.
2. 컴퓨터가 이해하기 쉬운 구조다.

직선모델을 사용하는 경우 매개변수 수 = $d+1$

2차 곡선 모델을 사용하는 경우 매개변수 수 = $d^2+d+1$

결국 매개변수가 많아질수록 경험을 통해 찾아야 할 대상이 많아진다 → 모델의 자유도가 높아진다 → 학습이 복잡해지고 어려워진다.

**차원의 저주**

- 차원이 높아짐에 따라 발생하는 현실적인 문제들
- 공간이 커지면 커질수록 데이터(경험)들이 지수적으로 더 많이 필요하다.

공간 변환을 사용하면 풀지 못했던 원문제를 심플한 모델로 풀 수 있다. (표현 문제, 표현 학습)

**표현 학습**

- 좋은 특징 공간을 자동으로 찾는 작업

**심층 학습**

표현학습의 하나로 **다수의 은닉층을 가진 신경망**을 이용하여 최적의 **계층적인 특징**을 학습

**기술 추세**

Rule-based system → Classic machine learning → Representation learning

- Rule-based는 어떤 룰에 대해 수행
- Classic에서는 사람들의 지식을 포함시켜서 특정 규칙을 찾음
- Classic 과 Representation의 차이는 사람이 개입하냐 개입하지 않느냐 차이이다.

**인공지능의 단계**

약인공지능 - 특정 task만 잘 품

강인공지능 - 인간이 할 수 있는 모든 지적인 업무 수행할 수 있음.

초인공지능 - 인간보다 훨씬 뛰어난 인공지능

## 기계학습2

적은 양의 데이터베이스로 어떻게 높은 성능을 달성하는가?

- 데이터 희소 가정
  - 필요한 과업에 대한 학습에 관련없는 데이터 발생확률은 0에 가깝다.
- 매니폴드 가정
  - 고차원의 데이터는 관련된 낮은 차원의 매니폴드에 가깝게 집중되어 있다.

**목적함수는 성능의 판단기준**

목적함수를 Loss가 최소가 되는 파라미터만을 찾는 것이 아닌, 내가 풀려고 하는 문제와 적합한 목적함수를 설정하는 것이 중요하다.

임의의 난수로 매개변수 값을 설정하고, 지속적으로 개선해서 최적해를 찾는다.

**최적화 이론**

- Convex - 최적해 1개
- non-Convex - 최적해 존재할 수도, 안할 수도 있음. 신경망(gradient descent 방법)

**기계 학습 알고리즘**

###

입력 : 훈련집합 X와 Y

출력 : 최적의 매개변수 $\hat{\theta}$

###

난수를 생성하여 초기 해 $\theta_1$을 설정한다.
$t=1$
while $j(\theta_t)$가 0, 0에 충분히 가깝지 않음:
$j(\theta_t)$가 작아지는 방향 $\vartriangle \theta_t$를 구한다.
$\theta_{t+1} = \theta_t + \vartriangle \theta_t$
$t=t+1$

$\hat\theta = \theta_t$

## 기계학습 3

DL에서 신경망의 Capacity를 적절하게 낮추기 위해 최근에 규제를 많이 사용

자유도가 낮은 경우, 평향이 크고 비슷한 모델을 얻는다(분산이 작음) → 낮은 변동

자유도가 높은 경우, 편향이 적고 크게 다른 모델을 얻는다(분산이 큼) → 높은 변동

(편향과 분산은 trade-off 관계이다.)

**기계 학습의 목표**

- target의 용량 == model 용량
- 낮은 평향과 낮은 분산을 가진 예측 모델을 만드는 것

**편향과 분산의 관계**

![https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTibnw8GyN-tRkM6i4in0a1SG-5yN6O3gJPvnA&usqp=CAU](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTibnw8GyN-tRkM6i4ina1SG-5yN6O3gJPvnA&usqp=CAU)

출처:https://www.google.com/url?sa=i&url=https%3A%2F%2Fcedar.buffalo.edu%2F~srihari%2FCSE676%2F5.2%2520MLBasics-Capacity.pdf&psig=AOvVaw1mxejLIe0v21OnjBFZjvkX&ust=1611067718297000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCOi9047dpe4CFQAAAAAdAAAAABAE

<br>

Underfitting은 보통 Bias, Overfitting은 Variance 때문에 발생

Generalization error를 최소로 하는 방법은 크게 일단 용량을 잡고 Regularize 로 깎는 방식을 최근에 사용

**Validation set을 이용한 모델 선택**

훈련데이터가 많을 때 부분 분할 하여 Validation set으로 사용

###(알고리즘) 검증집합을 이용한 모델 선택

for ($\Omega$(모델집합)에 있는 각각의 모델):

모델을 훈련집합으로 학습시킨다.

검증집합으로 학습된 모델의 성능을 측정한다.

가장 높은 성능을 보인 모델을 선택한다.

테스트 집합으로 선택된 모델의 성능을 측정한다.

###

![https://github.com/Ting-Kim/Ting-kim.github.io/blob/main/images/20210118_1.png?raw=true](https://github.com/Ting-Kim/Ting-kim.github.io/blob/main/images/20210118_1.png?raw=true)

**교차검증(Cross Validation)**

데이터 양이 적을 때(검증집합이 없을 때), 유용한 모델 선택 기법

![https://s3.amazonaws.com/higherlogicdownload/H2OAI/UploadedImages/Vcn3hx77RcGlSBB3RI69_16.png](https://s3.amazonaws.com/higherlogicdownload/H2OAI/UploadedImages/Vcn3hx77RcGlSBB3RI69_16.png)

출처:https://www.google.com/url?sa=i&url=https%3A%2F%2Fwww.h2o.ai%2Fcommunity%2Fglossary%2Fmodel-validation-hold-out-cross-validation&psig=AOvVaw1IjMiVbJl16_Nd2FKF-s7X&ust=1611067692578000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCJio_IHdpe4CFQAAAAAdAAAAABAD

<br>

데이터 양이 많을 때 검증집합은 어느정도 치우칠 수 있는데, 여기서는 Validation set을 여러 번 돌려서 평균을 도출하기 때문에 적은 양으로도 고도화된 일반화 성능을 확인할 수 있다.

**부트스트랩(Bootstrap)**

- 임의의 복원 추출 샘플링(sampling with replacement) 반복
- 데이터 분포가 불균형일 때 적용(데이터 분포에 치우침이 있을 때)
- 이상탐지, 보안 문제에서 많이 사용

![bootstrap_data_sampling](https://miro.medium.com/max/1010/1*YYom-NKDaZ-B7RB_891DgQ.png)

출처:https://www.google.com/url?sa=i&url=https%3A%2F%2Fmedium.com%2Ftime-to-work%2Fbagging-classifier-6261138b92d4&psig=AOvVaw1czCwKX8GYaOq6sWoPnvNc&ust=1611068723452000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCMiayergpe4CFQAAAAAdAAAAABAO

<br>

###(알고리즘) 부트스트랩을 이용한 모델 선택

입력 : 모델집합 $\Omega$, 훈련집합, 테스트집합, 샘플링 비율 $p(0<p\leq 1)$, 반복횟수 $T$

출력 : 최적 모델과 성능

---

for ($\Omega$(모델집합)에 있는 각각의 모델)

for ($i=1$ to $T$)

훈련집합 $X$에서 $pn$개 샘플을 뽑아 새로운 훈련집합 $X'$를 구성한다. 이때 대치를 허용한다.

$X'$로 모델을 학습시킨다.

$X-X'$를 이용하여 학습된 모델의 성능을 측정한다.

$T$개 성능을 평균하여 해당 모델의 성능으로 취한다.

가장 높은 성능을 보인 모델을 선택한다.

테스트집합으로 선택된 모델의 성능을 측정한다.

###

**데이터 확대(data augmentation)**

- 데이터 수집은 많은 비용이 든다
- 훈련집합의 샘플들을 변형(transform)한다. (원 데이터의 부류, 속성 등의 고유 특성 변하지 않을 만큼의 약간의 회전(rotation) 혹은 왜곡(warping))

**가중치 감쇠**

- 개선된 목적함수를 이용하여 가중치를 작게 조절하는 규제 기법
  - 목적함수에 규제 항(preference, 선호)을 추가하여 가중치 크기를 작게 유지해준다.
  - $\lambda$는 주어진 가중치의 감쇠 선호 정도를 제어
    - $\lambda=0$ : 감쇠 없음
    - 큰 $\lambda$는 가중치를 더 작아지도록 한다

**규제**

**지도 학습**

- 특징 벡터 X와 목표치 Y(정답 있음)가 모두 주어진 상황
- 보통 회귀와 분류 문제로 구분한다.

**비지도 학습**

- 특징 벡터 X는 주어지나, 목표치 Y가 주어지지 않는 상황 (정답이 없음)
- 군집화(clustering) 과업 (추천시스템, 고객 성향에 따른 맞춤 홍보 응용 등)
- Density estimation, 특징 공간 변환 과업 (예. PCA)

**강화 학습**

- 상대적 목표치가 주어지는데, 지도 학습과 다른 형태 (Agent의 Action을 통해 상황이 변경되는 것을 반영(보상(Reward)))
- 환경에 interactive한 상호작용을 통해서 학습하는 형태

**준지도 학습**

- 일부는 X, Y를 모두 가지지만, 나머지는 X만 가진 상황
- Y 데이터는 수작업이 필요하므로 최근 기업들이 많이 푸려고 하는 문제이다.

**오프라인 학습, 온라인 학습**

- 보통 오프라인 학습
- 온라인 학습은 추가로 발생하는 데이터에 대해 점증적 학습 수행

**결정론적 학습(deterministic learning)과 확률적 학습(Stochastic learning)**

- 결정론에서는 같은 데이터를 가지고 재학습 시 같은 예측 모델이 생성됨
- 확률적 학습은 학습 과정에서 확률 분포를 사용하므로 같은 데이터로 재학습하면 다른 예측 모델이 만들어진다. (ex. RBM, DBN)

**분별 모델(discriminative models)과 생성 모델(generative models)**

- 분별 모델은 P(y|x)의 추정에만 관심
- 생성 모델은 P(x) or P(x|y)를 추정한다.
  - 새로운 샘플을 생성할 수 있음
  - GAN, RBM은 생성 모델이다.
  - RNN(순환신경망)을 생성 모델로 활용하는 응용 예제도 있다.
